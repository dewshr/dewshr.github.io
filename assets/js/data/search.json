[ { "title": "Bar plot based on proportion for each individual group", "url": "/posts/pandas-proportion-plot/", "categories": "pandas", "tags": "pandas, seaborn, proportion, percentage, plot", "date": "2022-10-17 20:00:00 +0000", "snippet": "Lets load the datasetimport pandas as pdimport seaborn as snsdf = sns.load_dataset('tips')df.head()total_bill\ttip\tsex\tsmoker\tday\ttime\tsize0\t16.99\t1.01\tFemale\tNo\tSun\tDinner\t21\t10.34\t1.66\tMale\tNo\tSun\tDinner\t32\t21.01\t3.50\tMale\tNo\tSun\tDinner\t33\t23.68\t3.31\tMale\tNo\tSun\tDinner\t24\t24.59\t3.61\tFemale\tNo\tSun\tDinner\t4Lets say we want to distinguish the peoples preference for lucnch or dinner based on days. We can do that combining the pandas with seaborndf['time'].groupby(df['day']).value_counts(normalize=True).rename('proportion').reset_index().set_axis(['day','time','proportion'], axis=1).pipe((sns.barplot,'data'),x='day',y='proportion',hue='time')" }, { "title": "Divide pandas dataframe into bins", "url": "/posts/divide-dataframe-into-bins/", "categories": "python, pandas", "tags": "pandas, seaborn, cut, qcut, bin", "date": "2022-10-05 20:30:00 +0000", "snippet": "Dividing pandas dataframe into bins using qcut and cutLets use a sample dataframedf = sns.load_dataset('iris')df.head()Lets say we want to divide the dataframe into 5 bins based on the petal length. We can do that using qcut or cut.Using qcutqcut tries to divide the dataframe into bins such that similar proportion of data numbers are present in each bin.df['qcut_bin'] = pd.qcut(df['petal_length'],5)using cutIf we use cut to divide into 5 bins using petal_length, then it will generate the bins into 5 equal proportion based on the petal length values.df['cut_bin'] = pd.cut(df['petal_length'],5, include_lowest=True)The following picture represents different bins and numbers of data in each binplt.figure(figsize=(15,7))plt.subplot(1,2,1)sns.countplot(df['qcut_bin'])plt.xticks(rotation=90)plt.subplot(1,2,2)sns.countplot(df['cut_bin'])plt.xticks(rotation=90)" }, { "title": "Biological Data Resources", "url": "/posts/useful-websites/", "categories": "Bioinformatics", "tags": "genetics, data, resource, public_data", "date": "2022-09-27 18:30:00 +0000", "snippet": "Human protein AtlasIntActCistromeExpression AtlasARCHS4 (RNA Seq)GTExMetascapeDepmap portalcBioPortal" }, { "title": "Generate Frequency count table and motif logo from given fasta sequences", "url": "/posts/generate-motif-logo/", "categories": "Bioinformatics", "tags": "motif, logo, biopython, pwm, fasta, seaborn", "date": "2022-09-27 18:30:00 +0000", "snippet": "To generate a motif logo first we need to create a count table for the nucleotide bases from fasta sequences and then information matrix to plot motif logoCreate count table from fasta sequenceimport logomakerimport pandas as pdfrom Bio.Seq import Seqfrom Bio import motifsimport matplotlib.pyplot as pltimport seaborn as snsseq_list = []fasta = open(input_fasta_file,'r').readlines()for line in fasta: if not line.startswith('&gt;'):\t\t\tseq_list.append(line.upper().replace('\\n',''))\tprint('...... getting base counts .....\\n')\tinstances = [Seq(x.upper()) for x in seq_list]\tm = motifs.create(instances)\tm_df = pd.DataFrame(m.counts) m_df = m_df.iloc[0:10,:] m_df.head()# Running above for loop gives following output A\tC\tG\tT0\t239\t239\t351\t5931\t513\t231\t211\t4672\t281\t140\t771\t2303\t284\t451\t443\t2444\t410\t621\t156\t235Generate information matrix to generate motif logot_df = logomaker.transform_matrix(m_df, from_type = 'counts', to_type='information')sns.set(font_scale=1.5, style='white')plt.figure(figsize=(15,15))crp_logo=logomaker.Logo(t_df,font_name='Arial Rounded MT Bold')crp_logo.style_spines(visible=False)crp_logo.style_spines(spines=['left', 'bottom'], visible=True)plt.title('motif')plt.tight_layout()plt.savefig('/Users/dshresth/Downloads/test.pdf')Please make sure you have required packages for this to work. I also have the script here.Reference logomaker" }, { "title": "Single letter representation of ambiguous nucleotide", "url": "/posts/nucleotide_nomenclature/", "categories": "Genetics", "tags": "nucleotides, DNA", "date": "2022-09-23 22:00:00 +0000", "snippet": "Although DNA sequences are represented by four nucleotide bases (A,T,G,C) they can be represented by alternate letters based on different scenario. One of the example would be sequencing data, where N is used if nucleotide base can not be indentified for a particular position. It can also be used to represent motif sequences.The picture below represents the alternate representation for possible nucleotide bases at given position. Image taken from here.Here is another link, that talk into more details regarding this." }, { "title": "Histone Modifications and chromatin states", "url": "/posts/histone-modification/", "categories": "Epigenetics", "tags": "histone modification, enhancers, repressors, genetics, epigenetics", "date": "2022-09-13 17:30:00 +0000", "snippet": "Histone modification play an important role in gene regulation and based on different histon modification signatures, it can be used to annotate different chromatin states. The following picture provides the relation between different histone modifications and its functions.The above picture is retrieved from abcam. Here is the pdf version.Here are some other review papers related to histone modification: Linking DNA methylation and histone modification: patterns and paradigms (2009) Regulation of chromatin by histone modifications (2011) The interplay of histone modifications – writers that read (2015) Histone modifications and their role in epigenetics of atopy and allergic diseases (2018) Epigenetic modifications of histones in cancer (2019) Overview of Histone Modification (2021) " }, { "title": "Calculating phyloP conservation score over certain genomic region", "url": "/posts/get_phylop_conservation_score/", "categories": "Bioinformatics", "tags": "phylop, conservation, evolution, bedtools", "date": "2022-09-07 17:30:00 +0000", "snippet": "phyloP scores can be used to identify the evolionary rate of genomic sequences. Positive score represents slower evolution or more conserved sequence and negative score represents faster evolution.Pre-calculated phylop scores can be downloaded from UCSC site. The file is in bigwig format. Here, is step by step to calculate the phylop score for the given genomic region convert bigwig to bedGraph filebigWigToBedGraph hg19.100way.phyloP100way.bw hg19.100way.phyloP100way.bedGraphbigWigToBedGraph can be downloaded from here Use bedtools map to get mean score over the given genomic coordinatesbedtools map -a genomic_region.bed -b hg19.100way.phyloP100way.bedGraph -c 4 -o mean &gt; phylop_score.bedThe parameter -c 4 means the phylop score is present in column 4 in the bedGraph file. You can also change the output to be based on other operators such as sum, count, median etc.References paper tutorial phylop" }, { "title": "Create Genome Index file to map sequencing data", "url": "/posts/creating-genome-index-file/", "categories": "Bioinformatics", "tags": "index, bwa, star, bowtie2, kallisto, rna sequencing, dna sequencing, alignment", "date": "2022-09-03 05:30:00 +0000", "snippet": "There are several tools available map sequencing data to the reference genome. And for all of the tools index files needs to be generated first. Here are some of the tools and the syntax used to generate index file.DNA SequenceBurrows-Wheeler Alignment Tool (bwa)bwa index hg38.fasamtools faidx hg38.facut -f1,2 hg38.fa.fai &gt; hg38.sizesBowtie2bowtie2-build hg38.fa index_filenameRNA SequenceSpliced Transcripts Alignment to a Reference (STAR)STAR --runThreadN 20 --runMode genomeGenerate --genomeDir index_files/star_2.5.3a --genomeFastaFiles hg38.fa --sjdbGTFfile gencode.v41.annotation.gtf --sjdbOverhang 99sjdbOverhang value = readlength - 1kallistokallisto doesn’t allign sequencing reads to the genome, it performs pseudoalignment for transcript quantification using indexed transciptome. You can download the cdna fasta sequence from ensembl site.kallisto index -i index_filename hg38.cdna.faexample: index_filename = hg38_index.idxReference https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4631051/ https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3322381/" }, { "title": "Downloading data from UCSC table browser", "url": "/posts/downloading-data-from-ucsc-table-browser/", "categories": "Bioinformatics, Data", "tags": "ucsc, table browser, download, shell, awk", "date": "2022-08-31 22:50:00 +0000", "snippet": "UCSC table browser is a great tool that can be used to download different annotation data such as exon, intron, 5’ UTR, 3’ UTR etc.Here is an example to extract the exons from human genome version hg19: Select genome to Human Select group as Genes and Predictions Select your desired track. I have chosen GENCODE V41lift37. Select region to position if you have specific region of interest else, keep it at genome. Select output format as BED. This will generate output in bed format with each row representing as one exonic region. Give your output file name Select the output file type and then click get output. This will open another window, where you can select which genome region you want to extract. Look at the figures below for details.You can also download the gtf file, and parse the file to get the desired information such as TSS, intergenic region, exons, introns etc. You need to install bedtools for this.Extracting intergenic regionawk 'BEGIN{OFS=\"\\t\";} $3==\"gene\" {print $1,$4-1,$5}' hg19_gencode.v41lift37.annotation.gtf | sortBed | complementBed -i stdin -g hg19_chrom.sizes &gt; gencode.v41.intergenic_region.bedExtracting exon coordinatesawk '{OFS=\"\\t\"} $3==\"exon\" {print $1,$4-1,$5}' hg19_gencode.v41lift37.annotation.gtf | sortBed | bedtools merge -i stdin &gt; hg19_gencode_v41_exon.bedExtracting intron coordinatesawk '{OFS=\"\\t\"} $3==\"gene\" {print $1,$4-1,$5}' hg19_gencode.v41lift37.annotation.gtf | sortBed | bedtools subtract -a stdin -b stdin_test.bed &gt; hg19_gencode_v41_intron.bedThe hg38_chrom.sizes can be downloaded from this link. Or you can generate yourself from the fasta file.# First create index file using samtoolssamtools faidx hg19.fa# Extract column 1 and 2 from genome index filecut -f1,2 hg19.fa.fai &gt; hg19_chrom.sizes" }, { "title": "Download links for public data and tools", "url": "/posts/public-data-links/", "categories": "Bioinformatics, Data", "tags": "genome, download, data, bioinformatics, ucsc, ensembl", "date": "2022-08-31 22:30:00 +0000", "snippet": "This posts mainly consists of the links to different genomic data.UCSC Data linksUCSC hg19 ftp site hg19 fasta liftover chain files phastcon 100 way score phylop 100 way score multi species alignment fileUCSC hg38 ftp site hg38 fasta liftover chain files phastcon 100 way score phylop 100 way score multi species alignment fileUCSC tools linkGencode GTFhg38hg19Blacklist regionChip blacklist region" }, { "title": "Identify the strandedness of RNA Seq Data", "url": "/posts/identify-strandedness-of-RNA-Seq-data/", "categories": "Bioinformatics, RNASeq", "tags": "RSeQC, strandedness, featurecount, RNASeq, genetics", "date": "2022-08-30 23:00:00 +0000", "snippet": "Depending on the library preparation method, the RNA Seq data can be stranded or non-stranded. Here, is the link from Azenta, to better understand stranded vs non-stranded library preparation. Here is the screenshot taken from Hong Zheng which describes about the strandedness.Since different tools uses strand information to align and get the read counts for the genes, it is important to know the strandedness of RNA seq data. Mostly, for the public data strand information is not provided. The strandedness can be determined using the tool RSeQC. infer_experiment.py can be used to identify the strandedness. For details visit this link. Here, is the command example:infer_experiment.py -r hg19.refseq.bed12 -i Pairend_nonStrandSpecific_36mer_Human_hg19.bam#Output::This is PairEnd DataFraction of reads failed to determine: 0.0172Fraction of reads explained by \"1++,1--,2+-,2-+\": 0.4903Fraction of reads explained by \"1+-,1-+,2++,2--\": 0.4925If both 1++,1--,2+-,2-+ and 1+-,1-+,2++,2-- has equal proportion. The RNA Seq data is most likely unstranded. If 1++,1--,2+-,2-+ has more proportion, it is most likely forward stranded (FR, F1R2) else reverse stranded (RF, F2R1).There is another tool called how_are_we_stranded_here, which can also be used to identify the strandedness. On the background it also uses RSeQC. For RSeQC, you will need bam file, but for how_are_we_stranded_here you can directly use fastq files.The details regarding diffrent tools and their parameters for strandedness is provided here in this link from griffith lab." }, { "title": "Finding closest gene to the given genomic region", "url": "/posts/bedtools-closest/", "categories": "Bioinformatics, tools", "tags": "bedtools, genetics, genes, bioinformatics, awk", "date": "2022-08-26 21:15:00 +0000", "snippet": "To find the closest gene to the given genomic region, we will be using bedtools closest. Fist lets see our region of interest$ cat input_region.bedchr16\t566689\t566964\tid\t.\t+$ head -n 8 gencode.hg38.v41.bedchr1\t14404\t29570\tENSG00000227232.5\tWASH7P\t-chr1\t17369\t17436\tENSG00000278267.1\tMIR6859-1\t-chr1\t29554\t31109\tENSG00000243485.5\tMIR1302-2HG\t+chr1\t30366\t30503\tENSG00000284332.1\tMIR1302-2\t+chr1\t34554\t36081\tENSG00000237613.2\tFAM138A\t-chr1\t52473\t53312\tENSG00000268020.3\tOR4G4P\t+chr1\t57598\t64116\tENSG00000240361.2\tOR4G11P\t+chr1\t65419\t71585\tENSG00000186092.7\tOR4F5\t+Our region of interest is highlighted in yellow in the figure below, and there are 3 nearby genes (NHLRC4, PIGQ and PRR35). We can run the bedtools closest to get the nearest gene.$ bedtools closest -a input_region.bed -b gencode.hg38.v41.bed -D ref -t allchr16\t566689\t566964\tid\t.\t+\tchr16\t566995\t584109\tENSG00000007541.17\tPIGQ\t+\t32Here, using -D ref assigns input file (input_region.bed) used in -a parameter as reference. -t all used to report all the genes incase two genes are at exact same distance. But, we can see that although both NHLRC4 and PIGQ are very close to our region, only the closest is reported. We can use parameter -k to report to increase the number of nearest genes to be reported.$ bedtools closest -a input_region.bed -b gencode.hg38.v41.bed -D ref -t all -k 3chr16\t566689\t566964\tid\t.\t+\tchr16\t566995\t584109\tENSG00000007541.17\tPIGQ\t+\t32chr16\t566689\t566964\tid\t.\t+\tchr16\t567005\t569495\tENSG00000257108.2\tNHLRC4\t+\t42chr16\t566689\t566964\tid\t.\t+\tchr16\t560394\t565529\tENSG00000161992.6\tPRR35\t+\t-1161The last column represents the distance from our region of interest. Negative value means upstream and positive means downstream. To get more number of nearest genes, you can just increase the value in the -k, so that you don’t miss any genes if there are huge gene clusters in your region of intereset. But it also causes the addition of genes which are very far away. In this case, you can just filter the genes based on your desired distance.Lets say you want the genes which are less than 42 bp in downstream and less than 1200 bp in upstream. You can do it by simply using awk.$ bedtools closest -a input_region.bed -b gencode.hg38.v41.bed -D ref -t all -k 3 | awk '($13 &lt; 42 &amp;&amp; $13 &gt; -1200)'chr16\t566689\t566964\tid\t.\t+\tchr16\t566995\t584109\tENSG00000007541.17\tPIGQ\t+\t32chr16\t566689\t566964\tid\t.\t+\tchr16\t560394\t565529\tENSG00000161992.6\tPRR35\t+\t-1161" }, { "title": "Pandas Tricks", "url": "/posts/pandas-tricks/", "categories": "python, pandas", "tags": "pandas, filter, fimo, tricks, split, transription_factors, merge, reduce, compare, equal", "date": "2022-08-24 21:45:00 +0000", "snippet": "Splitting a row into multiple rows based on substring in a specific columnHere I have a dataframe with 3 columns (p1, p2 and tissue). In column p2 I have 2 genes separated by ';'import pandas as pdpp = pd.read_csv('promoter_promoter.csv', skiprows=2, names=['p1','p2','tissue'])pp.head()You can split each of those rows into separate rows by:pp = pp.assign(p2=pp[\"p2\"].str.split(\";\")).explode(\"p2\")pp.head(n=7)You can just use explode if the values are list. Inn the example below is the interaction data where one regions (a1) is interacting with multiple region (a2) which are presented in a listSplitting index into separate columnsLets say, we have a dataframe of interaction data with genomic region and gene it is interacting with. As shown in the figure below, the genomic coordinates is the index, and we want to split the index into 3 separate columns which can be done by:data[['chr','start','stop']] = list(data.index.str.replace(':','-').str.split('-'))Filter out the rows only selecting minimum value based on a specific columnI mainly use this to filter out the output file from program fimo. While scanning for motifs in a given sequnce, there can be multiple region within the sequence where a motif can be found. And I only want to keep those regions with the most significant motifs if there are multiple motifs identified in a given sequence.Here, in this dataframe, chr10:103057760-103058020 and chrX:23926122-23926382 has motifs in two positions and chr10:103362455-103362715 in three.import pandas as pdfimo_df = pd.read_csv('fimo.tsv',sep='\\t').iloc[0:-3,:]fimo_df.head()I am using iloc to remove last 3 rows from the fimo output file, which contains program run information. Now, since there are mulitple values for same sequence_name, I will only be keeping the one with lowest p-valuefimo_df = fimo_df.loc[fimo_df.groupby('sequence_name')['p-value'].idxmin()]fimo_df.head()Filtering dataframe if substring in a column matches to any elements of a listLets assume we have a dataframe as below:df.head()And we want to filter out the dataframe based on our list of transcription factors (TF) as:tf_list = ['BATF','PBX3']Since, the TF we are interested is a substring in column motif_id, we can’t use df[df['motif_id']].isin(tf_list). So, we can achieve that by:In the code, above we are also using .upper() function to convert all letters to uppercase if there are any lowercase letters.Merge multiple dataframes based on a columnHere, there are 4 dataframes, and I want to merge them based on the common column name id.import pandas as pdfrom functools import reducedf_list = [df1, df2, df3, df4]merged_df = reduce(lambda left, right: pd.merge(left, right, on=['id'], how='outer'), df_list)merged_df = merged_df.dropna()Compare if two columns are equal in pandas dataframedf['column1'].equals(df['column2'])This will True or False as output." }, { "title": "Cheat Sheet", "url": "/posts/cheat-sheets/", "categories": "pdf", "tags": "linux, conda, git", "date": "2022-08-23 05:30:00 +0000", "snippet": "LinuxLinux Cheat SheetGitGithub Cheat SheetCondaConda Cheat Sheet" }, { "title": "Add frequency count for each category on box plot", "url": "/posts/add-count-numbers-on-box-plot/", "categories": "python, pandas", "tags": "seaborn, matplotlib, plots, text_annotation", "date": "2022-08-22 22:00:00 +0000", "snippet": "Here I will show how to add frequency count to the each category in the box plot. For this we will use the searborn provided example dataset.First, lets load the dataset:import searborn as snsimport numpy as npimport matplotlibimport matplotlib.pyplot as pltmatplotlib.rcParams['pdf.fonttype'] = 42matplotlib.rcParams['ps.fonttype'] = 42data = sns.load_dataset('tips')tips.head()total_bill\ttip\tsex\tsmoker\tday\ttime\tsize0\t16.99\t1.01\tFemale\tNo\tSun\tDinner\t21\t10.34\t1.66\tMale\tNo\tSun\tDinner\t32\t21.01\t3.50\tMale\tNo\tSun\tDinner\t33\t23.68\t3.31\tMale\tNo\tSun\tDinner\t24\t24.59\t3.61\tFemale\tNo\tSun\tDinner\t4After that, lets create two separate functions to get the all the annotation informations.def hue_annotation_counts(df, label, yaxis_val, hue_label, order=None, hue_order=None): if order==None: order = list(df[label].unique()) if hue_order == None: hue_order = list(df[hue_label].unique()) width=0.8 n_levels = len(df[hue_label].unique()) each_width = width / n_levels offsets = np.linspace(0, width - each_width, n_levels) offsets -= offsets.mean() pos = [x+o for x in np.arange(len(order)) for o in offsets] counts = df.groupby([label,hue_label])[yaxis_val].size() counts = counts.reindex(pd.MultiIndex.from_product([order, hue_order ])) medians = df.groupby([label,hue_label])[yaxis_val].median() medians = medians.reindex(pd.MultiIndex.from_product([order, hue_order])) return pos, counts, medians, order, hue_orderdef label_annotation_counts(df, label, yaxis_val, order=None): if order==None: order = list(df[label].unique()) counts = df.groupby(label)[yaxis_val].size() counts = counts.reindex(index=order) medians = df.groupby(label)[yaxis_val].median() medians = medians.reindex(index=order) return range(len(counts)), counts, medians, orderNow, plotting boxplots without hue information:plt.figure(figsize=(11,7))pos, counts, medians, order = label_annotation_counts(temp, 'day','total_bill', order)sns.boxplot(x = 'day', y='total_bill',data= temp, order=order)for p,n,m in zip(pos,counts,medians): if not np.isnan(m): plt.annotate('N={:.0f}'.format(n), xy=(p, m), xycoords='data', ha='center', va='bottom', size=15) plt.tight_layout()plt.ylabel('Total Bill')plt.xlabel('Day')plt.xticks(rotation=90)Now, plotting boxplots with extra information (‘sex’), which sub-divides x-label into further two categories. If you have your own order and hue order, you can pass that while calling the function.plt.figure(figsize=(11,8))pos, counts, medians, order, hue_order = hue_annotation_counts(temp, 'day','total_bill','sex')sns.boxplot(x = 'day', y='total_bill',hue = 'sex',data= temp, order=order, hue_order=hue_order)for p,n,m in zip(pos,counts,medians): if not np.isnan(m): plt.annotate('N={:.0f}'.format(n), xy=(p, m), xycoords='data', ha='center', va='bottom', size=10) plt.tight_layout()plt.xticks(rotation=90)" }, { "title": "Generate Motif Sequence From Pwm Matrix", "url": "/posts/generate-motif-sequence-from-pwm-matrix/", "categories": "python", "tags": "motif, DNA, sequence, pwm", "date": "2022-08-22 19:00:00 +0000", "snippet": "I am using PWM (Position Weight Matrix) file in meme format downloaded from JASPAR database as the input file. I am using random.choices from python to randomly generate the nucleotide motif sequence using the probability value for each position as weights.import randomimport numpy as npdef generate_nucleotide(probability): if sum(probability) ==1: return random.choices(['A','C','G','T'], weights=probability) elif sum(probability) &lt; 1: diff = 1 - sum(probability) index = probability.index(max(probability)) probability[index] = probability[index] + diff return random.choices(['A','C','G','T'], weights=probability) else: diff = 1 - sum(probability) index = probability.index(max(probability)) probability[index] = probability[index] - diff return random.choices(['A','C','G','T'], weights=probability)pwm = open('tf_selected_pwm.txt','r').read().split('letter-')[1].split('\\n')pwm = list(filter(None, pwm))motif = ''for i in range(1, len(pwm)-1): p = [np.round(float(x),2) for x in pwm[i].split()] #print(p) motif = motif + generate_nucleotide(p)[0] print(motif)After running this, you will get something like this TTGCCACCAGAGGGAGCTA." }, { "title": "Linux Tips", "url": "/posts/linux-tips/", "categories": "linux", "tags": "awk, sed, shell, condition, tar, split", "date": "2022-08-22 18:30:00 +0000", "snippet": "Create a directory with multiple sub-directoriesmkdir -p output_folder/{raw_data,temp_data,result,log_folder}Go to specific line number using vivi +14 filenameThis will open the file at line 14Split a large file into multiple smaller filessplit -l 500 input_filename output_filenameIf there are 2000 lines in a file, this will split the input file into 4 files each with 500 lines.Find duplicate lines in a fileuniq -D filenameCompress and decompress filecompress: tar -zcvf compressed.tar.gz *.csvextract: tar -xzvf compressed.tar.gzChange the value of specific column given a condition (if else)awk '{print $1,($2&lt;0)? 0 : $2,$3}Add a new column with unique idawk '{FS=OFS=\"\\t\"}{ print $1\"\\t\"$2\"\\t\"$3\"\\tid-\"NR\"\\t\"$4; }' filename &gt; output_filenameFind common lines between two filescomm -12 &gt;(sort file1) &lt;(sort file2)Replace empty columnn with certain valueawk -F, 'BEGIN {FS=OFS}{if ($7==\"\") $7=\"changed\"; else $7=$7; print}' input_file.txt &gt; modified_input.txtHere, 7th column is replaced by value changed if its empty else, original value is keptGetting all the rows with 2 columns having same valuesawk '($4==$5)' input_file.txt &gt; output_file.txtFiltering rows based on certain column valueawk '($4 &lt; 5)' input_file.txt &gt; output_file.txtFilering using multiple conditionsawk '($4 &lt;5 &amp;&amp; $4 &gt;0)' input_file.txt &gt; output_file.txtGetting mean value for specific columnawk {total +=$4} END {print total/NR} input_file.txtGetting unique values based on multiple column comparisonawk -F\"\\t\" 'seen[$1,$2,$3,$4]++' input_file,txt &gt; output_file.txtRemoving first row without opening filesed '1d' input_file.txt &gt; output_file.txtChanging the values of filesed 's/-/\\t/g' input_file.txt &gt; output_file.txtSometimes there are carriage returns (\\r, ^M) in file, which can mess up the file processing, you can remove it by:sed 's/\\r//g' input_file.txt &gt; output_file.txt" }, { "title": "Creating Multiple Subplots in One Figure Using Seaborn Python", "url": "/posts/creating-multiple-subplots-using-seaborn-python/", "categories": "python, pandas", "tags": "seaborn, matplotlib, subplots, rcparam", "date": "2022-08-22 18:30:00 +0000", "snippet": "If you want to include multiple plots in a single figure, you can do that by creating axes. Here, is the sample code for that.In this section of code I am just loading the example dataset.import searborn as snsimport matplotlibimport matplotlib.pyplot as pltmatplotlib.rcParams['pdf.fonttype'] = 42matplotlib.rcParams['ps.fonttype'] = 42data = sns.load_dataset('tips')tips.head()total_bill\ttip\tsex\tsmoker\tday\ttime\tsize0\t16.99\t1.01\tFemale\tNo\tSun\tDinner\t21\t10.34\t1.66\tMale\tNo\tSun\tDinner\t32\t21.01\t3.50\tMale\tNo\tSun\tDinner\t33\t23.68\t3.31\tMale\tNo\tSun\tDinner\t24\t24.59\t3.61\tFemale\tNo\tSun\tDinner\t4After loading the data you can use following code for subplotscols = ['sex','smoker','day', 'time']fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10,10))fig.subplots_adjust(wspace=0.5, hspace=0.5)for ax, x in zip(axes.flatten(), cols): sns.boxplot(x=x, ax=ax, y='total_bill', data =tips) ax.set_title(f'comparison of total bills among different {x}', pad=15)plt.savefig('/your/path/plot.pdf')In the above code, wspace and hspace adjusts the space between plots and pad set the space between the subplot title and plot. You should be getting the image shown below.You can also use:plt.subplot(num_row, num_column, figure1)sns.boxplot()plt.subplot(num_row, num_column, figure2)sns.boxplot()plt.subplot(num_row, num_column, figure3)sns.boxplot()plt.subplot(num_row, num_column, figure4)sns.boxplot()" }, { "title": "Creating a static webpage", "url": "/posts/creating-static-webpage/", "categories": "webpage_tutorial", "tags": "webpage, github pages, jekyll, markdown, link", "date": "2022-08-22 16:30:00 +0000", "snippet": "Getting StartedI used the Jekyll chirpy theme for this webpage. Follow the following steps to create your own webpage.Steps: First go to the Chirpy github page. Click on the Chirpy starter. This will redirect you to create new github repository. Name the repository as &lt;your user name&gt;.github.io. So, in my case, I created dewshr.github.io Clone your git repository to your local computer using git clone. Install the required dependencies trough this Jekyll link. There is OS specific documentation you can follow. I am using macOS, here are the commands I used: brew install chruby ruby-install ruby-install ruby echo \"source $(brew --prefix)/opt/chruby/share/chruby/chruby.sh\" &gt;&gt; ~/.bash_profile echo \"source $(brew --prefix)/opt/chruby/share/chruby/auto.sh\" &gt;&gt; ~/.bash_profile echo \"chruby ruby-3.1.2\" &gt;&gt; ~/.bash_profile source ~/.bash_profile (or you can restart the terminal) gem install jekyll bundle (run this inside your local github repository (dewshr.github.io)) I already have homebrew installed.Launching web page locallyRun the command bundle exec jekyll s. This will give you the server address (example: http://127.0.0.1:4000/). After you go to the server address it should look something like thisTo customize the names and links to the social media, go to the configuration file config.yml and make changes over there.Adding new postsCreate a new file with extension .md inside the folder _posts. The file name should follow in this order: 2022-08-22-creating-static-webpage.md. Inside the file you need to have this on the top:---title: Creating a static webpageauthor: Dewan Shresthadate: 2022-08-22 11:30:00 -0500 categories: [webpage_tutorial]tags: [webpage, github pages, jekyll]pin: true---The last number on the date represents the time zone. For more details follow this linkLinking another post within a postYou can link another markdown page using post_url. In the image below gtf file is the text that will appear in the page that will link to another page. 2022-08-31-public-data-links is the name of another markdown file that you want to link. You don’t need to put .md after the name.Building and Deploying website through githubBefore we deploy, there is also another file (pages-deploy.yml) that needs to be changed. I used vi .github/workflows/pages-deploy.yml to edit the file.Since, I am running on macOS. I changed runs-on section from linux to macOS-12. You might also need to change the ruby version. I changed it to 3.1.2. You can get the version information by running ruby -v in terminal. In my case, running ruby -v gives version as 3.1.2p20. You do not need to include p20 in the version information.Now after making all these changes, you can push the changes to github repository: git add . git commit -m 'first commit' git pushAfter this go to the your github repository and click on Actions tab. You can see the status of your workflow over there.The successful built and deployment will have the green check mark as shown above. That was not the case for me. You can click on the failed section to get the detailed log of the event.I had to run following command to fix it:bundle lock --add-platform rubyAfter successful build and deployment, go to settings and then click on pages and then change the branch to gh-pages and save. NOTE: Everytime you make changes you need to git add . and git commit -m 'message' and git push." } ]
